name: dashboard_csv
services:
  # PostgreSQL Database 
  # Esta seção é responsável por criar o banco de dados PostgreSQL e inicializar o schema e as tabelas
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: analytics_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - analytics-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend 1 - Auth & Trigger (Flask/Python)
  # Esta seção é responsável por criar o backend 1 que é responsável por autenticar o usuário e disparar o pipeline
  backend1-auth:
    build:
      context: ./backend1-auth
      dockerfile: Dockerfile
    container_name: backend1-auth
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=development
      - JWT_SECRET=minha-chave-secreta-jwt-super-segura
      - PIPELINE_URL=http://pipeline:8080/trigger
    depends_on:
      - pipeline
    networks:
      - analytics-network

  # Backend 2 - Query API (Go)
  # Esta seção é responsável por criar o backend 2 que é responsável por consultar o banco de dados PostgreSQL e retornar os dados
  backend2-api:
    build:
      context: ./backend2-api
      dockerfile: Dockerfile
    container_name: backend2-api
    ports:
      - "8080:8080"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/analytics_db
      - JWT_SECRET=minha-chave-secreta-jwt-super-segura
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - analytics-network

  # Data Source Server (Python)
  # Esta seção é responsável por criar o data source server que é responsável por servir o arquivo CSV
  data-source:
    build:
      context: ./data-source
      dockerfile: Dockerfile
    container_name: data-source
    ports:
      - "3000:3000"
    volumes:
      - ./orders.csv:/app/orders.csv
    networks:
      - analytics-network

  # Pipeline (Go)
  # Esta seção é responsável por criar o pipeline que é responsável por ingerir os dados do data source server e transformar os dados
  pipeline:
    build:
      context: ./pipeline
      dockerfile: Dockerfile
    container_name: pipeline
    ports:
      - "8081:8080"
    environment:
      - DATA_SOURCE_URL=http://data-source:3000
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/analytics_db
      - TRANSFORMER_URL=http://transformer:8080/transform
      - PORT=8080
    depends_on:
      - data-source
      - postgres
      - transformer
    networks:
      - analytics-network

  # Transformer (Python)
  # Esta seção é responsável por criar o transformer que é responsável por transformar os dados do pipeline e salvar no banco de dados
  transformer:
    build:
      context: ./transformer
      dockerfile: Dockerfile
    container_name: transformer
    ports:
      - "8082:8080"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/analytics_db
      - PORT=8080
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - analytics-network

  # Frontend (React)
  # Esta seção é responsável por criar o frontend que é responsável por exibir os dados do backend 2
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3001:3000"
    depends_on:
      - backend1-auth
      - backend2-api
    networks:
      - analytics-network

  # pgAdmin - Interface gráfica para PostgreSQL
  # Esta seção é responsável por criar o pgAdmin que é responsável por exibir a interface gráfica do PostgreSQL
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    ports:
      - "5050:80"
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    depends_on:
      - postgres
    networks:
      - analytics-network

networks:
  analytics-network:
    driver: bridge

volumes:
  postgres_data:


